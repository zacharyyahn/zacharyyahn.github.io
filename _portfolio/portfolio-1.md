---
title: "Attenion Attacks on Transformer-based Object Detection"
excerpt: "First PhD project in the Distributed Data-Intensive Systems Lab (DiSL). <br/><br/><img src='/images/tog1.png'>"
collection: portfolio
---

To date, white-box adversarial methods are only capable of attacking convolutional neural network (CNN)-based object detection models. In this project, I devise a novel attention-based attack that is capable of corrupting both CNN-based and transformer-based approaches. Early results show that this method is effective against many of the state-of-the-art object detection models, having implications for important applications like autonomous driving, radiology, facial recognition, and more. 

This project is currently in development.

Check out the code base [here](http://github.com/zacharyyahn/TOG_plus) <br>

 <img src='/images/tog_none.gif'><img src='/images/tog_vanish.gif'><img src='/images/tog_fab.gif'><img src='/images/tog_mislabel.gif'> <br>
 Examples of this attack borrowed from its predecessor, [TOG](https://github.com/git-disl/TOG/tree/master). Variations include vanishing, fabrication, mislabeling, and random untargeted.

